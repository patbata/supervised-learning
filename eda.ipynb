{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-12T04:02:14.529989Z",
     "start_time": "2024-02-12T04:02:14.183773Z"
    }
   },
   "outputs": [],
   "source": [
    "# import general libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# import helper functions\n",
    "from src.utils.DataSetup import DataSetup\n",
    "import src.model.modeling\n",
    "# set up plot parameters\n",
    "plt.rcParams.update({'font.size': 16})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Cleaning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Wine Data set-up"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# load wine data\n",
    "wine_data = pd.read_csv('../data/wine-data/wine.data')\n",
    "wine_data.columns = ['class','alcohol','malic_acid','ash','alcalinity_of_ash','magnesium',\n",
    "                     'total_phenols','flavanoids','nonflavanoid_phenols','proanthocyanins',\n",
    "                     'color_intensity','hue','OD280/OD315_of_diluted_wines','proline']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-12T04:02:14.561473Z",
     "start_time": "2024-02-12T04:02:14.530616Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datapoints: 177\n",
      "Features: alcohol, malic_acid, ash, alcalinity_of_ash, magnesium, total_phenols, flavanoids, nonflavanoid_phenols, proanthocyanins, color_intensity, hue, OD280/OD315_of_diluted_wines, proline (13 attributes)\n",
      "Missing Values: 0\n",
      "--------------Target Counts--------------\n",
      "Target Variable: class\n",
      "2    71 (40.11%)\n",
      "1    58 (32.77%)\n",
      "3    48 (27.12%)\n",
      "dtype: object\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "DataSetup.save_train_test_split() got an unexpected keyword argument 'X'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 8\u001B[0m\n\u001B[1;32m      5\u001B[0m wine\u001B[38;5;241m.\u001B[39mdescribe_dataset(sort_index\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m# initialize split on all features\u001B[39;00m\n\u001B[0;32m----> 8\u001B[0m \u001B[43mwine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msave_train_test_split\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mwine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      9\u001B[0m \u001B[43m                            \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mwine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     10\u001B[0m \u001B[43m                            \u001B[49m\u001B[43mtest_split\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.2\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     11\u001B[0m \u001B[43m                            \u001B[49m\u001B[43mrandom_state\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m2024\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     12\u001B[0m \u001B[43m                            \u001B[49m\u001B[43mstore_splits\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mTypeError\u001B[0m: DataSetup.save_train_test_split() got an unexpected keyword argument 'X'"
     ]
    }
   ],
   "source": [
    "# initialize data setup object to split to train and test\n",
    "wine = DataSetup(wine_data, 'class')\n",
    "\n",
    "# check out dataset\n",
    "wine.describe_dataset(sort_index=False)\n",
    "\n",
    "# initialize split on all features\n",
    "wine.save_train_test_split(X=wine.X,\n",
    "                            y=wine.y,\n",
    "                            test_split=0.2,\n",
    "                            random_state=2024,\n",
    "                            store_splits=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-12T04:02:14.703474Z",
     "start_time": "2024-02-12T04:02:14.565847Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "wine_data.columns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# tsne viz on wine\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\n",
    "tsne_results = tsne.fit_transform(wine_data.drop('class', axis=1))\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "pca_result = pca.fit_transform(wine_data.drop('class', axis=1))\n",
    "\n",
    "wine_data['pca-one'] = pca_result[:,0]\n",
    "wine_data['pca-two'] = pca_result[:,1]\n",
    "wine_data['pca-three'] = pca_result[:,1]\n",
    "wine_data['tsne-2d-one'] = tsne_results[:,0]\n",
    "wine_data['tsne-2d-two'] = tsne_results[:,1]\n",
    "\n",
    "sns.scatterplot(\n",
    "    x=\"tsne-2d-one\", y=\"tsne-2d-two\",\n",
    "    hue=\"class\",\n",
    "    data=wine_data,\n",
    "    legend=\"full\",\n",
    "\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# axes instance\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "ax = Axes3D(fig, auto_add_to_figure=False)\n",
    "fig.add_axes(ax)\n",
    "\n",
    "# get colormap from seaborn\n",
    "cmap = ListedColormap(sns.color_palette().as_hex())\n",
    "\n",
    "# plot\n",
    "sc = ax.scatter(wine_data['pca-one'],\n",
    "                wine_data['pca-two'],\n",
    "                wine_data['pca-three'], s=40,\n",
    "                c=wine_data['class'], marker='o', cmap=cmap, alpha=1)\n",
    "\n",
    "# legend\n",
    "plt.legend(*sc.legend_elements(), bbox_to_anchor=(1.05, 1), loc=2)\n",
    "\n",
    "ax.set_xlabel('X Label')\n",
    "ax.set_ylabel('Y Label')\n",
    "ax.set_zlabel('Z Label')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Poker Data set-up"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# read poker data\n",
    "poker_data = pd.read_csv('../data/poker-data/poker-hand.data', header=None)\n",
    "poker_data.columns = ['S1','C1','S2','C2','S3','C3','S4','C4','S5','C5','hand']\n",
    "\n",
    "# save numerical version of data (\"one-hot\" encoding)\n",
    "poker_num = poker_data.copy()\n",
    "\n",
    "# dictionaries for cleaning\n",
    "poker_suits = {1:'Hearts',2:'Spades',3:'Diamonds',4:'Clubs'}\n",
    "poker_hands = {0:'Nothing in hand',1:'One pair',2:'Two pairs',3:'Three of a kind',\n",
    "                             4:'Straight',5:'Flush',6:'Full house',7:'Four of a kind',\n",
    "                             8:'Straight flush',9:'Royal flush'}\n",
    "# clean suit columns\n",
    "for i in range(1,6):\n",
    "    poker_data['S'+str(i)] = poker_data['S'+str(i)].map(poker_suits)\n",
    "\n",
    "# clean hand categories\n",
    "poker_data.hand = poker_data.hand.map(poker_hands)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# initialize data setup object\n",
    "poker = DataSetup(poker_data, 'hand')\n",
    "\n",
    "# save numerical version of data (\"one-hot\" encoding)\n",
    "# poker.dataset_onehot = poker_num\n",
    "\n",
    "# check out dataset\n",
    "poker.describe_dataset(sort_index=False)\n",
    "\n",
    "# initialize split on all features\n",
    "poker.save_train_test_split(X=poker.dataset_onehot[poker.onehot_features],\n",
    "                            y=poker.y,\n",
    "                            test_split=0.2,\n",
    "                            random_state=2024,\n",
    "                            store_splits=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "poker.num_features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Student Performance Data set-up"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# read student data\n",
    "student_data = pd.read_csv('../data/student-data/student.csv', sep=';')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "student_data.G3\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\n",
    "tsne_results = tsne.fit_transform(student_data.drop('G3', axis=1))\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "pca_result = pca.fit_transform(student.drop('G3', axis=1))\n",
    "\n",
    "wine_data['pca-one'] = pca_result[:,0]\n",
    "wine_data['pca-two'] = pca_result[:,1]\n",
    "wine_data['pca-three'] = pca_result[:,1]\n",
    "wine_data['tsne-2d-one'] = tsne_results[:,0]\n",
    "wine_data['tsne-2d-two'] = tsne_results[:,1]\n",
    "\n",
    "sns.scatterplot(\n",
    "    x=\"tsne-2d-one\", y=\"tsne-2d-two\",\n",
    "    hue=\"G3\",\n",
    "    data=student_data,\n",
    "    legend=\"full\",\n",
    "\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from scipy.stats import lognorm\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#make this example reproducible\n",
    "np.random.seed(1)\n",
    "\n",
    "#generate dataset that contains 1000 log-normal distributed values\n",
    "lognorm_dataset = lognorm.rvs(s=.5, scale=math.exp(1), size=1000)\n",
    "\n",
    "#create Q-Q plot with 45-degree line added to plot\n",
    "output=student_data.loc[:,'G3']\n",
    "output.value_counts().sort_index().plot(kind='bar')\n",
    "plt.title(f\"Student Dataset \"\n",
    "              f\"G3 Grade Distribution\")\n",
    "plt.xlabel(f\"G3\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.savefig(f\"student_target_distribution_unclean.png\")\n",
    "plt.clf()\n",
    "# fig = sm.qqplot(output, line='45')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# create overlapping loss curves\n",
    "names = ['wine','student']\n",
    "import seaborn as sns\n",
    "\n",
    "# create loss curves\n",
    "for name in names:\n",
    "    # initialize data setup object\n",
    "    loss = pd.read_csv(f\"results/{name}/final/losses_{name}.csv\")\n",
    "\n",
    "    # # create lineplot with confidence intervals\n",
    "    sns.lineplot(data=loss, x='fold', y='loss', markers=True,\n",
    "                 dashes=False, legend=True, label=name)\n",
    "    # sns.scatterplot(data=loss_avg, x='fold', y='loss', size=2)\n",
    "\n",
    "        # add labels\n",
    "    plt.legend()\n",
    "    plt.title(f'Loss Curve of Neural Network (Split into {5} Folds)')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epochs')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "    # initialize data setup object\n",
    "student = DataSetup(student_data, 'G3')\n",
    "\n",
    "# check out dataset\n",
    "student.describe_dataset(sort_index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "training_features = [\n",
    "            'school_MS',\n",
    "            'sex_M',\n",
    "            'address_U', 'famsize_LE3', 'Pstatus_T',\n",
    "            'Mjob_health', 'Mjob_other', 'Mjob_services',\n",
    "            'Mjob_teacher',\n",
    "            'Fjob_health', 'Fjob_other', 'Fjob_services',\n",
    "            'Fjob_teacher',\n",
    "            'reason_home', 'reason_other', 'reason_reputation',\n",
    "            'guardian_mother', 'guardian_other',\n",
    "            'schoolsup_yes', 'famsup_yes',\n",
    "            'paid_yes', 'activities_yes',\n",
    "            'nursery_yes', 'higher_yes',\n",
    "            'internet_yes', 'romantic_yes',\n",
    "            'age',\n",
    "            'Medu', 'Fedu',\n",
    "            'traveltime', 'studytime',\n",
    "            'failures',\n",
    "            'famrel', 'freetime', 'goout', 'Dalc', 'Walc',\n",
    "            'health', 'absences',\n",
    "            'G1', 'G2',\n",
    "        ]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(training_features)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "student.dataset_onehot[student.num_features+student.onehot_features]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "poker.dataset_onehot"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Decision Trees"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# per model\n",
    "1. Validation curve for 2 hyperparameters (fix range and choice)\n",
    "2. Learning curve\n",
    "3. Have interesting findings\n",
    "4. Grid search to get optimal model in the end"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# import modeling\n",
    "from importlib import reload\n",
    "reload(modeling)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# initialize the classifier\n",
    "modeling.plot_validation_curve('DecisionTree',\n",
    "                               wine,\n",
    "                               'max_depth',\n",
    "                               range(1, 10),\n",
    "                               k_folds=5,\n",
    "                               scoring='f1_weighted')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# initialize the classifier\n",
    "modeling.plot_validation_curve('DecisionTree',\n",
    "                               wine,\n",
    "                               'min_samples_split',\n",
    "                               np.arange(4,40,4),\n",
    "                               k_folds=5,\n",
    "                               scoring='f1_weighted')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "strings = '[0.0001, 0.05, 0.01]'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eval('DecisionTreeClassifier()')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Split test set\n",
    "- From train set, use cross_validate and KFold (or StratifiedKFold) to get cv metrics (train scores, test scores)\n",
    "  - either do a learning curve or a validation curve\n",
    "    - learning curve: plot train and test scores vs. dataset size\n",
    "        - sample the dataset (e.g. 10%, 20%, 30%, ..., 100%), then run cv\n",
    "    - validation curve: plot train and test scores vs. hyperparameter value"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import (\n",
    "    cross_validate,\n",
    "    GridSearchCV,\n",
    "    KFold\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=5, shuffle=True, random_state=2024)\n",
    "ci_cv = pd.DataFrame()\n",
    "plot=True\n",
    "k_folds=5\n",
    "\n",
    "for train_percent in np.linspace(0.1, 1, 10):\n",
    "    # cut down train set\n",
    "    X_train_temp, y_train_temp = poker.X_train.sample(frac=train_percent), poker.y_train.sample(frac=train_percent)\n",
    "\n",
    "    # create decision tree\n",
    "    clf, y_pred = model_algos.decision_tree_setup(X_train_temp,\n",
    "                                                  poker.X_test,\n",
    "                                                  y_train_temp,\n",
    "                                                  poker.y_test,\n",
    "                                                  max_depth=8,\n",
    "                                                  show_metrics=False)\n",
    "    # results from tree\n",
    "    results = cross_validate(clf, X_train_temp, y_train_temp, cv=cv,\n",
    "                                   return_train_score=True)\n",
    "\n",
    "    # fix results into dataframe\n",
    "    ci_cv_temp = pd.DataFrame(results)\n",
    "    ci_cv_temp['percentage'] = train_percent\n",
    "    ci_cv = pd.concat([ci_cv, ci_cv_temp], axis=0)\n",
    "\n",
    "    # summarize and get average\n",
    "    summary_cv = ci_cv.groupby('percentage').mean().reset_index()\n",
    "\n",
    "# plot results\n",
    "if plot:\n",
    "    # create lineplot with confidence intervals\n",
    "    sns.lineplot(data=ci_cv, x='percentage', y='train_score', markers=True,\n",
    "                 dashes=False, legend=True, label='Train')\n",
    "    sns.lineplot(data=ci_cv, x='percentage', y='test_score', markers=True,\n",
    "                 dashes=False, legend=True, label='Test')\n",
    "    sns.scatterplot(data=summary_cv, x='percentage', y='train_score')\n",
    "    sns.scatterplot(data=summary_cv, x='percentage', y='test_score')\n",
    "\n",
    "    # add labels\n",
    "    plt.title(f'Decision Tree Cross Validation ({k_folds} Folds)')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Percentage of Training Data Used')\n",
    "    plt.xlim(0.1,1)\n",
    "\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ci_cv"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# use cross validate\n",
    "for k in range(3,6):\n",
    "    cross_validate = model_algos.decision_tree_depth(depths=range(1, 10),\n",
    "                                                     X_train=poker.X_train,\n",
    "                                                     X_test=poker.X_test,\n",
    "                                                     y_train=poker.y_train,\n",
    "                                                     y_test=poker.y_test,\n",
    "                                                     k_folds=k)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Appendix"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# read heart disease data\n",
    "heart_disease_data = pd.read_csv('../heart-disease-data/processed.cleveland.data', header=None)\n",
    "heart_disease_data.columns = ['age','sex','cp','trestbps','chol','fbs','restecg','thalach',\n",
    "                              'exang','oldpeak','slope','ca','thal','num']\n",
    "\n",
    "# clean using strings\n",
    "heart_disease_data.sex = heart_disease_data.sex.map({1:'male',0:'female'})\n",
    "heart_disease_data.cp = heart_disease_data.cp.map({1:'typical angina',2:'atypical angina',\n",
    "                                                   3:'non-anginal pain',4:'asymptomatic'})\n",
    "heart_disease_data.fbs = heart_disease_data.fbs.map({1:True,0:False})   # if fasting blood sugar > 120mg/dl\n",
    "heart_disease_data.restecg = heart_disease_data.restecg.map({0:'normal',1:'ST-T wave abnormality',\n",
    "                                                             2:'left ventricular hypertrophy'})\n",
    "heart_disease_data.exang = heart_disease_data.exang.map({1:True,0:False})   # if exercise induced angina\n",
    "heart_disease_data.slope = heart_disease_data.slope.map({1:'upsloping',2:'flat',3:'downsloping'}) # slope of peak exercise ST segment\n",
    "heart_disease_data.thal = heart_disease_data.thal.map({3:'normal',6:'fixed defect',7:'reversable defect'})\n",
    "\n",
    "# remove fields with lots of missing data\n",
    "heart_disease_data = heart_disease_data.drop(['thal'], axis=1)\n",
    "\n",
    "# check out dataset\n",
    "helper.describe_dataset(heart_disease_data, \"num\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
